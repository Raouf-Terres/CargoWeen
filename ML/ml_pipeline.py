import pandas as pd
import numpy as np
from pymongo import MongoClient
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, classification_report, precision_score, recall_score
from sklearn.impute import SimpleImputer
import joblib
import mlflow
import mlflow.sklearn
from mlflow.models.signature import infer_signature
from mlflow.tracking import MlflowClient
from pymongo.server_api import ServerApi

def load_and_prepare_data(connection_string, db_name, collection_name):
    client = MongoClient(
        connection_string,
        server_api=ServerApi('1'),
        tls=True,
        tlsAllowInvalidCertificates=True  # N√©cessaire dans certains environnements CI
    )
    
    try:
        client.admin.command('ping')
        print("Connexion √† MongoDB √©tablie avec succ√®s")
        
        db = client[db_name]
        collection = db[collection_name]
        
        cursor = collection.find({})
        df = pd.DataFrame(list(cursor))
        
        if '_id' in df.columns:
            df.drop('_id', axis=1, inplace=True)
            
        df = clean_data(df)
        
        cols_to_keep = ["postalAddress", "region", "country", "city", "postalCode", 
                       "prixKm", "prixArrivee", "douane", "companyName"]
        df = df[[col for col in cols_to_keep if col in df.columns]]
        
        return df
        
    except Exception as e:
        print(f"Erreur de connexion √† MongoDB: {e}")
        return None
    finally:
        client.close()

def clean_data(df):
    df = df.drop_duplicates()
    
    if 'postalAddress' in df.columns:
        df['postalAddress'] = df['postalAddress'].str.strip().fillna('Adresse Inconnue')
    
    numeric_cols = ['prixKm', 'prixArrivee', 'douane']
    for col in numeric_cols:
        if col in df.columns:
            df[col] = df[col].astype(str)
            df[col] = df[col].str.replace('[^\d.,]', '', regex=True)
            df[col] = df[col].str.replace(',', '.')
            df[col] = pd.to_numeric(df[col], errors='coerce')
    
    for col in ['region', 'city', 'country', 'companyName']:
        if col in df.columns:
            df[col] = df[col].fillna('Inconnu')
    
    if 'postalCode' in df.columns:
        df['postalCode'] = pd.to_numeric(df['postalCode'], errors='coerce')
        df['Code_Prefix'] = df['postalCode'].astype(str).str[:2].fillna('00')
    
    return df

def prepare_for_ml(df, target_col='prixKm'):
    if target_col in df.columns:
        median_price = df[target_col].median()
        y = np.where(df[target_col] > median_price, '√©lev√©', 'faible')
    else:
        raise ValueError(f"Colonne cible '{target_col}' introuvable")
    
    categorical_cols = ['postalAddress', 'region', 'country', 'city', 'Code_Prefix']
    categorical_cols = [col for col in categorical_cols if col in df.columns]
    
    numeric_cols = [col for col in df.columns 
                   if col not in categorical_cols and col != target_col 
                   and pd.api.types.is_numeric_dtype(df[col])]
    
    encoders = {}
    for col in categorical_cols:
        le = LabelEncoder()
        df[col] = le.fit_transform(df[col].astype(str))
        encoders[col] = le
    
    features_numeric = df[numeric_cols]
    features_categorical = df[categorical_cols]
    
    numeric_imputer = SimpleImputer(strategy='median')
    categorical_imputer = SimpleImputer(strategy='most_frequent')
    
    X_numeric = numeric_imputer.fit_transform(features_numeric)
    X_categorical = categorical_imputer.fit_transform(features_categorical)
    
    scaler = StandardScaler()
    X_numeric_scaled = scaler.fit_transform(X_numeric)
    
    X = np.concatenate([X_numeric_scaled, X_categorical], axis=1)
    feature_names = numeric_cols + categorical_cols
    
    return X, y, scaler, {'numeric': numeric_imputer, 'categorical': categorical_imputer}, encoders, feature_names

def train_and_evaluate_models(X, y, feature_names=None):
    mlflow.set_tracking_uri("http://34.76.98.147")
    mlflow.set_experiment("Transport_Logistique_Optimization")

    models = {
        "KNN": KNeighborsClassifier(n_neighbors=5),
        "RandomForest": RandomForestClassifier(n_estimators=100, random_state=42),
        "LogisticRegression": LogisticRegression(max_iter=1000, random_state=42),
        "SVM": SVC(kernel='linear', probability=True, random_state=42),
       }

    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)
    
    best_score = -1
    best_model = None
    best_run_id = None
    results = {}

    for name, model in models.items():
        with mlflow.start_run(nested=True, run_name=name):
            try:
                model.fit(X_train, y_train)
                y_pred = model.predict(X_test)
                accuracy = accuracy_score(y_test, y_pred)
                
                mlflow.log_params(model.get_params())
                mlflow.log_metrics({
                    "accuracy": accuracy,
                    "precision": precision_score(y_test, y_pred, pos_label='√©lev√©'),
                    "recall": recall_score(y_test, y_pred, pos_label='√©lev√©')
                })

                signature = infer_signature(X_train, model.predict(X_train))
                mlflow.sklearn.log_model(
                    model,
                    artifact_path=f"{name.lower()}_model",
                    signature=signature,
                    registered_model_name="Transport_Logistique_Model"
                )

                results[name] = {
                    'accuracy': accuracy,
                    'model': model,
                    'run_id': mlflow.active_run().info.run_id
                }

                if accuracy > best_score:
                    best_score = accuracy
                    best_model = name
                    best_run_id = mlflow.active_run().info.run_id

            except Exception as e:
                print(f"Erreur avec {name}: {str(e)}")
                continue

    if best_run_id:
        client = MlflowClient()
        model_version = client.search_model_versions(f"run_id='{best_run_id}'")[0].version
        client.transition_model_version_stage(
            name="Transport_Logistique_Model",
            version=model_version,
            stage="Production"
        )
        print(f"\n‚úÖ Meilleur mod√®le ({best_model}) marqu√© comme 'Production' dans MLflow.")

    return results, best_model, X_test, y_test

def load_production_model():
    client = MlflowClient()
    model_name = "Transport_Logistique_Model"
    
    try:
        # Alternative √† get_latest_versions
        latest_versions = client.search_model_versions(f"name='{model_name}'")
        prod_models = [v for v in latest_versions if v.current_stage == "Production"]
        
        if not prod_models:
            raise ValueError("Aucun mod√®le en production trouv√©")
            
        prod_model = prod_models[0]
        model_uri = f"models:/{model_name}/{prod_model.version}"
        model = mlflow.sklearn.load_model(model_uri)
        print(f"\n‚úÖ Mod√®le en production charg√© : {prod_model.run_id}")
        return model
    except Exception as e:
        print(f"\n‚ùå Erreur lors du chargement du mod√®le : {str(e)}")
        return None

def run_ml_pipeline(connection_string, db_name, collection_name):
    print("="*60)
    print("D√âMARRAGE DU PIPELINE DE MACHINE LEARNING".center(60))
    print("="*60)

    try:
        print("\n√âtape 1: Chargement des donn√©es depuis MongoDB...")
        df = load_and_prepare_data(connection_string, db_name, collection_name)
        
        if df is None or df.empty:
            print("\nImpossible de charger les donn√©es depuis MongoDB ou DataFrame vide")
            return None
            
        print("\nDonn√©es charg√©es avec succ√®s depuis MongoDB:")
        print(f"- Nombre d'enregistrements: {len(df)}")
        print(f"- Colonnes disponibles: {list(df.columns)}")
    except Exception as e:
        print(f"\nErreur lors du chargement des donn√©es: {str(e)}")
        return None

    try:
        print("\n√âtape 2: Pr√©paration des donn√©es pour le machine learning...")
        X, y, scaler, imputer, encoders, feature_names = prepare_for_ml(df)
        print("\n‚úÖ Donn√©es pr√©par√©es pour le ML:")
        print(f"- Nombre de caract√©ristiques: {len(feature_names)}")
        print(f"- Distribution des classes: {dict(zip(*np.unique(y, return_counts=True)))}")
    except Exception as e:
        print(f"\n‚ùå Erreur lors de la pr√©paration des donn√©es: {str(e)}")
        return None

    print("\nüîß Entra√Ænement des mod√®les en cours...")
    results, best_model_name, X_test, y_test = train_and_evaluate_models(X, y, feature_names)
    
    if best_model_name in results:
        print(f"\nüèÜ Meilleur mod√®le s√©lectionn√©: {best_model_name}")
        print(f"- Accuracy (test): {results[best_model_name].get('accuracy', 'N/A'):.4f}")
        
        y_pred = results[best_model_name]['model'].predict(X_test)
        print("\nüìù Rapport de classification d√©taill√©:")
        print(classification_report(y_test, y_pred))
    else:
        print("\n‚ùå Aucun mod√®le valide produit")
        return None

    try:
        joblib.dump({
            'model': results[best_model_name]['model'],
            'scaler': scaler,
            'feature_names': feature_names,
            'encoders': encoders
        }, "best_model.pkl")
        print("\nüíæ Mod√®le sauvegard√© localement dans 'best_model.pkl'")

        production_model = load_production_model()
        
        if production_model:
            sample_data = X[:1]
            prediction = production_model.predict(sample_data)
            print(f"\nüîÆ Test de pr√©diction du mod√®le en production : {prediction}")
    except Exception as e:
        print(f"\n‚ùå Erreur lors de la gestion des mod√®les: {str(e)}")

    return df
